{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec568094",
   "metadata": {},
   "source": [
    "# Hyper-parameter Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29a701",
   "metadata": {},
   "source": [
    "Hyper-parameters to be investigated: <br>\n",
    "1. Number of hidden layers <br>\n",
    "2. Number of nodes per layer <br>\n",
    "3. The type of activation function used in each layer <br>\n",
    "4. The learning rate <br>\n",
    "5. The number of epochs <br>\n",
    "\n",
    "Baseline parameters used for the network (unless otherwise specified):\n",
    "- Leaky ReLU activation function for hidden layers\n",
    "- Sigmoid activation function for the output layer \n",
    "- A single training cycle consists of 2000 epochs \n",
    "- Default learning rate is 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62036f1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import funcs\n",
    "import network as net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de465e",
   "metadata": {},
   "source": [
    "**Step 1:** Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data (each row is an instance)\n",
    "data = pd.read_csv(\"data_banknote_authentication.txt\",\n",
    "    sep=\",\",\n",
    "    header=None,\n",
    ")\n",
    "x = data.iloc[:, 0:3].to_numpy()\n",
    "y = data.iloc[:, 4].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e3d72",
   "metadata": {},
   "source": [
    "**Step 2:** Method for initiating and training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nr_layers, nr_nodes, activation_func, learning_rate, nr_epochs):\n",
    "    layers = []\n",
    "    for i in range(nr_layers):\n",
    "        layers.append(net.layer(nr_nodes, activation_func))\n",
    "    layers.append(net.layer(1, funcs.sigmoid)) # add the output layer with sigmoid as activation func\n",
    "    \n",
    "    n = net.network(x, layers, y, alpha=learning_rate)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    acc, loss  = n.learn(nr_epochs)\n",
    "    t_time = time.time() - start_time # training time\n",
    "\n",
    "    return acc, loss, t_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c353c",
   "metadata": {},
   "source": [
    "## 1. Number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be007a",
   "metadata": {},
   "source": [
    "Investigate the accuracy of neural networks with varying numbers of hidden layers (0 to 10). To isolate the effect of the number of hidden layers on a network's performance, each layer has a single nodes. Performance metrics used to evaluate the model are - average accuracy, loss and training time calculated form 10 trial runs of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e6d19",
   "metadata": {},
   "source": [
    "**Step 1:** Train the network and collect the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "nr_reps = 3\n",
    "nr_models = 5\n",
    "\n",
    "accuracy_layers = np.zeros(( nr_models, epochs))\n",
    "loss_layers =  np.zeros(( nr_models, epochs))\n",
    "t_time_layers = np.zeros(( nr_models, nr_reps))\n",
    "\n",
    "# for each set of hyperparameters investigated, re-train the network a set number of times\n",
    "for i in range (nr_reps):\n",
    "    for j in range(nr_models):\n",
    "        an, ln, tn = train_nn(j, 1, funcs.leaky_relu, 0.05, 2000)\n",
    "\n",
    "        # Averaging as we go via weighted sum\n",
    "        accuracy_layers[j] += an / nr_reps\n",
    "        loss_layers[j] += ln / nr_reps\n",
    "        t_time_layers[j] += tn / nr_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62632ea3",
   "metadata": {},
   "source": [
    "**Step 2:** Plot the performance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(accuracy_layers.shape[0]):\n",
    "    plt.plot(accuracy_layers[i], linestyle = 'solid', label = f'{i} Hidden Layer(s)')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs the number of hidden layers')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76847064",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(loss_layers.shape[0]):\n",
    "    plt.plot(loss_layers[i], linestyle = 'solid', label = f'{i} Hidden Layer(s)')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Accuracy vs the number of hidden layers')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd1c34",
   "metadata": {},
   "source": [
    "## 2. Number of nodes per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272f649",
   "metadata": {},
   "source": [
    "Next, investigate the effect of the number of nodes per layer on a network's performance. In the previous experiment networks with 2, 4, and 6 hidden layers performed best (**perhaps this is not the best way to reason about this, the accuracy in the previous section changes dramatically from run to run, as well if the activation is changed**), therefore these architectures will be used as baseline and the number of nodes altered (exclude networks with single node per layer as this scenario was explored in the previous section).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c118ecb",
   "metadata": {},
   "source": [
    "#### 2.1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd2e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "nr_reps = 3\n",
    "nr_models = 4\n",
    "\n",
    "accuracy_nodes = np.zeros(( nr_models, epochs))\n",
    "loss_nodes =  np.zeros(( nr_models, epochs))\n",
    "t_time_nodes = np.zeros(( nr_models, nr_reps))\n",
    "\n",
    "# for each set of hyperparameters investigated, re-train the network a set number of times\n",
    "for i in range (nr_reps):\n",
    "    for j in range(nr_models):\n",
    "        an, ln, tn = train_nn(2, j+2, funcs.leaky_relu, 0.05, 2000)\n",
    "\n",
    "        # Averaging as we go via weighted sum\n",
    "        accuracy_nodes[j] += an / nr_reps\n",
    "        loss_nodes[j] += ln / nr_reps\n",
    "        t_time_nodes[j] += tn / nr_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f2c15",
   "metadata": {},
   "source": [
    "#### 2.2. Plot the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(accuracy_nodes.shape[0]):\n",
    "    plt.plot(accuracy_nodes[i], linestyle = 'solid', label = f'2 Hidden Layers: {i+2} Nodes')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs the number of nodes per layer')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(loss_nodes.shape[0]):\n",
    "    plt.plot(loss_nodes[i], linestyle = 'solid', label = f'2 Hidden Layers: {i+2} Nodes')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Accuracy vs the number of nodes per layer')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b711efe",
   "metadata": {},
   "source": [
    "## 3. Type of activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e52b86",
   "metadata": {},
   "source": [
    "Explore the effect of activation function used in the hidden layers on the model's performance. For the final output to be in the range between 0 and 1 (necessary to evaluate the model's performance using the loss function), sigmoid activation function is used in the output layer.\n",
    "Activation functions used:\n",
    "- Logistic activation function (**sigmoid**)\n",
    "- Hyperbolic tangent activation function (**tanh**)\n",
    "- Rectified Linear Unit activation function (**relu**)\n",
    "- Leaky ReLU activation function (**leaky_relu**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b26263",
   "metadata": {},
   "source": [
    "#### 3.1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "nr_reps = 3\n",
    "nr_models = 4\n",
    "\n",
    "accuracy_func = np.zeros(( nr_models, epochs))\n",
    "loss_func =  np.zeros(( nr_models, epochs))\n",
    "t_time_func = np.zeros(( nr_models, nr_reps))\n",
    "\n",
    "activation_funcs = [funcs.sigmoid, funcs.tanh, funcs.relu, funcs.leaky_relu]\n",
    "# for each set of hyperparameters investigated, re-train the network a set number of times\n",
    "for i in range (nr_reps):\n",
    "    for j in range(nr_models):\n",
    "        an, ln, tn = train_nn(2, 5, activation_funcs[j], 0.05, 2000)\n",
    "\n",
    "        # Averaging as we go via weighted sum\n",
    "        accuracy_func[j] += an / nr_reps\n",
    "        loss_func[j] += ln / nr_reps\n",
    "        t_time_func[j] += tn / nr_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bad1ed",
   "metadata": {},
   "source": [
    "#### 3.2. Plot the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_names = [\"Sigmoid\", \"Tanh\", \"ReLU\", \"Leaky ReLU\"]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(accuracy_func.shape[0]):\n",
    "    plt.plot(accuracy_func[i], linestyle = 'solid', label = f'Activation function: {funcs_names[i]}')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Accuracy vs the activation function')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs_names = [\"Sigmoid\", \"Tanh\", \"ReLU\", \"Leaky ReLU\"]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(loss_func.shape[0]):\n",
    "    plt.plot(loss_func[i], linestyle = 'solid', label = f'Activation function: {funcs_names[i]}')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Accuracy vs the activation function')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f6f9a",
   "metadata": {},
   "source": [
    "## 4. Learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa114f1b",
   "metadata": {},
   "source": [
    "Baseline architecture of the network used: 2 hidden layers with 2 nodes per layer (**justification?**). <br>\n",
    "Learning rates tested:\n",
    "- 0.05\n",
    "- 0.01\n",
    "- 0.005\n",
    "- 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7d455",
   "metadata": {},
   "source": [
    "#### 4.1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79904263",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "nr_reps = 3\n",
    "nr_models = 4\n",
    "\n",
    "accuracy_alpha = np.zeros(( nr_models, epochs))\n",
    "loss_alpha =  np.zeros(( nr_models, epochs))\n",
    "t_time_alpha = np.zeros(( nr_models, nr_reps))\n",
    "\n",
    "learning_rate = [0.05, 0.01, 0.005, 0.001]\n",
    "\n",
    "# for each set of hyperparameters investigated, re-train the network a set number of times\n",
    "for i in range (nr_reps):\n",
    "    for j in range(nr_models):\n",
    "        an, ln, tn = train_nn(2, 5, funcs.relu, learning_rate[j], 2000)\n",
    "\n",
    "        # Averaging as we go via weighted sum\n",
    "        accuracy_alpha[j] += an / nr_reps\n",
    "        loss_alpha[j] += ln / nr_reps\n",
    "        t_time_alpha[j] += tn / nr_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fc1a4",
   "metadata": {},
   "source": [
    "#### 4.2. Plot the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(accuracy_alpha.shape[0]):\n",
    "    plt.plot(accuracy_alpha[i], linestyle = 'solid', label = f'Learning rate: {learning_rate[i]}')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs learning rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(accuracy_alpha.shape[0]):\n",
    "    plt.plot(loss_alpha[i], linestyle = 'solid', label = f'Learning rate: {learning_rate[i]}')\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs learning rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac4de0",
   "metadata": {},
   "source": [
    "## 5. Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_epochs(epochs):\n",
    "    nr_reps = 3\n",
    "    nr_models = 2\n",
    "\n",
    "    acc = np.zeros((nr_models, epochs))\n",
    "    loss =  np.zeros((nr_models, epochs))\n",
    "    t_time = np.zeros((nr_models, nr_reps))\n",
    "\n",
    "    learning_rate = [0.05, 0.001]\n",
    "\n",
    "    # for each set of hyperparameters investigated, re-train the network a set number of times\n",
    "    for _ in range (nr_reps):\n",
    "        for j in range(nr_models):\n",
    "            an, ln, tn = train_nn(2, 5, funcs.relu, learning_rate[j], epochs)\n",
    "\n",
    "            # Averaging as we go via weighted sum\n",
    "            acc[j] += an / nr_reps\n",
    "            loss[j] += ln / nr_reps\n",
    "            t_time[j] += tn / nr_reps\n",
    "    \n",
    "    return acc, loss, t_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4000, loss4000, t_time4000 = train_nn_epochs(4000)\n",
    "acc6000, loss6000, t_time6000 = train_nn_epochs(6000)\n",
    "acc8000, loss8000, t_time8000 = train_nn_epochs(8000)\n",
    "acc10000, loss10000, t_time10000 = train_nn_epochs(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Plot the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "learning_rate = [0.05, 0.001]\n",
    "\n",
    "for i in range(acc4000.shape[0]):\n",
    "    axs[0, 0].plot(acc4000[i], label=f'Alpha: {learning_rate[i]}')\n",
    "    axs[0, 1].plot(acc8000[i])\n",
    "    axs[1, 0].plot(acc6000[i])\n",
    "    axs[1, 1].plot(acc10000[i])\n",
    "\n",
    "axs[0, 0].set_title('4000 Epochs')\n",
    "axs[0, 1].set_title('8000 Epochs')\n",
    "axs[1, 0].set_title('6000 Epochs')\n",
    "axs[1, 1].set_title('10000 Epochs')\n",
    "\n",
    "fig.suptitle(\"Accuracy vs total epochs\", fontsize=16)\n",
    "fig.legend()\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Epochs', ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "learning_rate = [0.05, 0.001]\n",
    "\n",
    "for i in range(loss4000.shape[0]):\n",
    "    axs[0, 0].plot(loss4000[i], label=f'Alpha: {learning_rate[i]}')\n",
    "    axs[0, 1].plot(loss8000[i])\n",
    "    axs[1, 0].plot(loss6000[i])\n",
    "    axs[1, 1].plot(loss10000[i])\n",
    "\n",
    "axs[0, 0].set_title('4000 Epochs')\n",
    "axs[0, 1].set_title('8000 Epochs')\n",
    "axs[1, 0].set_title('6000 Epochs')\n",
    "axs[1, 1].set_title('10000 Epochs')\n",
    "\n",
    "fig.suptitle(\"Loss vs total epochs\", fontsize=16)\n",
    "fig.legend()\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Epochs', ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "reshaped = (accuracy_nodes.reshape(4, 2000))\n",
    "df = pd.DataFrame(data=reshaped, columns=['2 Nodes', '3 Nodes', '4 Nodes', '5 Nodes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results in this plot make no sense, but perhaps could be useful to present data in this way."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31d85c8c4349c595bff3342b0980d2ed891b4161c611c2485aef65641e7a00b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('biocomp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
